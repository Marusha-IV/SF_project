# Задача проекта - построить модель кредитного скоринга для вторичных клиентов банка на основе заданного массива данных.

## I Анализ исходных данных
### 1 Набор данных для моделирования содержит 73799 записей.
### 2 В заданной выборке можно выделить следующие типы данных:
#### - дата ['app_date'], преобразуется в числовые данные;
#### - числовые данные Col_Num = ['client_id', 'age', 'decline_app_cnt', 'score_bki', 'bki_request_cnt', 'region_rating', 'income' + 'app_date'];
#### - числовые данные дискретные Col_Num_diskr = ['good_work', 'home_address', 'work_address', 'sna', 'first_time', 'default'], подразумевают численную оценку заданного параметра/качества по некоторым курупнённым категориям (типа близко/далеко, давно/недавно);
#### - категориальные переменные Col_Nom = ['education', 'sex', 'car', 'car_type', 'foreign_passport'].
#### (данные Col_Num_diskr и Col_Nom являются категориальными, часть из них бинарные часть имеет более 2 категорий. Для бинарных целесообразно приведение к числовому формату со значениями 0/1. Если данные разбиты по более чем 2 категорям имеются 2 варианта: преобразовать столбец в n столбцов со значениями 0/1 для каждой категории, если категории равнозначны в контексте задачи, или провести численную оценку заданного параметра/качества по некоторым курупнённым категориям, если прослеживается возможность интерпритации категорий по степени выраженности качества. В данном случае целесообразным представляется второе.)
### 3 Набор данных является не сбалансированным по переменной default, значение которой необходимо предсказать по условию задачи. В заданной выборке кол-во клиентов совершивших дефолт составляет ~ 13% от общего кол-ва клиентов.

## II Анализ конктетных переменных и их влияния на качество решения показал, что:
#### - переменные 'client_id' и 'app_date' после нормализации имеют практически 100% корреляцию (можно сделать вывод о том, что идентификатор клиента формируется на основе даты подачи заявки).
#### - для 'age', 'decline_app_cnt', 'bki_request_cnt', 'region_rating', 'income' целесообразно применить логарифмирование, с целью получения более равномерного распределения признака и уменьшения влияния выбросов (данное преобразование предполагается вместо удаления выбросов, т.к. распределение признака является не симметричным, однако распределение значений соответствует здравому смыслу и не выглядит аномальным), однако это не приводит к существенному повышению точности.
#### - добавление полиномиальных признаков (конкретных) дает небольшой выйгрыш, но не приводит к существенному повышению точности.
#### - формирование более сбалансированной выборки (за счет дополнения копиями или исключения части данных) не приводит к существенному повышению точности по критерию ROC AUC, однако приводит к существенному повышению точности определения возможности default.
#### - ризнаки 'sna', 'home_address', 'decline_app_cnt', 'score_bki', 'region_rating' в основном обеспечивают полученную точность решения, использование остальных данных не приводит к существенному повышению точности.

## III Полученный лучший результат по заданной метрике
### ROC_AUC = 0,74551 (результат получен для несбалансированной выборки и не является корректным в рамках решаемой задачи, что показывает ошибочность выбора данной метрики, предпочтительней в данном случае F1 и confusion matrix)